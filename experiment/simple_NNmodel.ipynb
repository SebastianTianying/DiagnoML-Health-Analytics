{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPThEjGg0jUw"
   },
   "source": [
    "### Building the Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NR_M9nWN-K8B"
   },
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xTvHzGCxXkqp"
   },
   "source": [
    "Now, display a batch of 8 negative and 8 positive pictures. You can rerun the cell to see a fresh batch each time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sn9m9D3UimHM"
   },
   "source": [
    "#### Data Preprocessing\n",
    "\n",
    "Now, let's use `keras.preprocessing.image.ImageDataGenerator` class to create our train and validation dataset and normalize our data. \n",
    "\n",
    "It's important to normalize our data because data going into our CNN to improve its overall performance. We will use the `rescale` parameter to scale our image pixel values from [0, 255] to [0,1].\n",
    "\n",
    "In each generator, we specify the source directory of our images, the classes, the input image size, the batch size (how many images to process at once), and class mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6YI-I9hkGWrL",
    "outputId": "c9901fb2-2b96-47dc-ab6b-7d528049a427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5232 images belonging to 3 classes.\n",
      "Found 624 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 120 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train',  # This is the source directory for training images\n",
    "        target_size=(200, 200),  # All images will be resized to 200x200\n",
    "        batch_size=120)\n",
    "\n",
    "# Flow validation images in batches of 19 using valid_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'test',  # This is the source directory for training images\n",
    "        target_size = (200, 200),  # All images will be resized to 200x200\n",
    "        batch_size = 19,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oqBkNBJmtUv"
   },
   "source": [
    "## Building the Model from Scratch\n",
    "\n",
    "But before we continue, let's start defining the model:\n",
    "\n",
    "Step 1 will be to import tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qvfZg3LQbD-5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnhYCP4tdqjC"
   },
   "source": [
    "Let's then add a Flatten layer that flattens the input image, which then feeds into the next layer, a Dense layer, or fully-connected layer, with 128 hidden units. Finally, because our goal is to perform binary classification, our final layer will be a sigmoid, so that the output of our network will be a single scalar between 0 and 1, encoding the probability that the current image is of class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PixZ2s5QbYQ3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 17:22:59.599907: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-07 17:22:59.599929: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = (200,200,3)), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9EaFDP5srBa"
   },
   "source": [
    "The model.summary() method call prints a summary of the NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ZKj8392nbgP",
    "outputId": "1387f011-da04-4a1c-f2b5-80ce2e8252f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 120000)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               15360128  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,360,515\n",
      "Trainable params: 15,360,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmtkTn06pKxF"
   },
   "source": [
    "The \"output shape\" column shows the transformation of the dimensions of each layer as a result of the convolution and max pooling - convolution will reduce the layer size by a bit due to padding, and max pooling will halve the output size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEkKSpZlvJXA"
   },
   "source": [
    "Next, we'll configure the specifications for model training. We will train our model with the `binary_crossentropy` loss. We will use the `Adam` optimizer. [Adam](https://wikipedia.org/wiki/Stochastic_gradient_descent#Adam) is a sensible optimization algorithm because it automates learning-rate tuning for us (alternatively, we could also use [RMSProp](https://wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp) or [Adagrad](https://developers.google.com/machine-learning/glossary/#AdaGrad) for similar results). We will add accuracy to `metrics` so that the model will monitor accuracy during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8DHWhFP_uhq3"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mu3Jdwkjwax4"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fb1_lgobv81m",
    "outputId": "53a71cf4-9b01-4293-caf2-1a4aca3f73e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 17:23:00.501275: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-03-07 17:23:00.657413: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 47.4388 - accuracy: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 17:23:02.204014: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 970ms/step - loss: 47.4388 - accuracy: 0.4375 - val_loss: 132.3265 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 88.0705 - accuracy: 0.2333 - val_loss: 32.0712 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 51.5722 - accuracy: 0.3417 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 68.4194 - accuracy: 0.4292 - val_loss: 7.3794 - val_accuracy: 0.1421\n",
      "Epoch 5/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 52.6225 - accuracy: 0.2958 - val_loss: 0.3966 - val_accuracy: 0.9000\n",
      "Epoch 6/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 29.6587 - accuracy: 0.6000 - val_loss: 5.8963e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 15.1045 - accuracy: 0.5667 - val_loss: 24.6099 - val_accuracy: 0.0579\n",
      "Epoch 8/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 23.3625 - accuracy: 0.2333 - val_loss: 24.6300 - val_accuracy: 0.0579\n",
      "Epoch 9/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 9.1636 - accuracy: 0.5333 - val_loss: 0.0489 - val_accuracy: 0.9789\n",
      "Epoch 10/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 12.4941 - accuracy: 0.5958 - val_loss: 0.1521 - val_accuracy: 0.9526\n",
      "Epoch 11/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 12.2417 - accuracy: 0.6167 - val_loss: 1.8594 - val_accuracy: 0.7842\n",
      "Epoch 12/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.1062 - accuracy: 0.6542 - val_loss: 5.7255 - val_accuracy: 0.3421\n",
      "Epoch 13/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 8.0662 - accuracy: 0.4208 - val_loss: 0.2479 - val_accuracy: 0.9211\n",
      "Epoch 14/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.8074 - accuracy: 0.5750 - val_loss: 0.2027 - val_accuracy: 0.9474\n",
      "Epoch 15/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.4971 - accuracy: 0.6708 - val_loss: 6.6819 - val_accuracy: 0.2737\n",
      "Epoch 16/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.8052 - accuracy: 0.4708 - val_loss: 0.5665 - val_accuracy: 0.8842\n",
      "Epoch 17/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.8751 - accuracy: 0.6208 - val_loss: 0.0233 - val_accuracy: 0.9947\n",
      "Epoch 18/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.5084 - accuracy: 0.6979 - val_loss: 5.5050 - val_accuracy: 0.2421\n",
      "Epoch 19/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.7737 - accuracy: 0.5417 - val_loss: 0.9776 - val_accuracy: 0.8316\n",
      "Epoch 20/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.6344 - accuracy: 0.6958 - val_loss: 0.0339 - val_accuracy: 0.9895\n",
      "Epoch 21/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.9995 - accuracy: 0.5667 - val_loss: 1.7784 - val_accuracy: 0.6526\n",
      "Epoch 22/45\n",
      "2/2 [==============================] - 1s 808ms/step - loss: 2.7605 - accuracy: 0.6094 - val_loss: 0.3450 - val_accuracy: 0.9368\n",
      "Epoch 23/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.7351 - accuracy: 0.6375 - val_loss: 0.0541 - val_accuracy: 0.9895\n",
      "Epoch 24/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.4676 - accuracy: 0.6458 - val_loss: 3.4471 - val_accuracy: 0.3211\n",
      "Epoch 25/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.5786 - accuracy: 0.5000 - val_loss: 0.0485 - val_accuracy: 0.9895\n",
      "Epoch 26/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.1035 - accuracy: 0.7125 - val_loss: 2.2190 - val_accuracy: 0.5316\n",
      "Epoch 27/45\n",
      "2/2 [==============================] - 1s 1s/step - loss: 2.2526 - accuracy: 0.6094 - val_loss: 0.0403 - val_accuracy: 0.9895\n",
      "Epoch 28/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.1157 - accuracy: 0.6375 - val_loss: 1.6413 - val_accuracy: 0.5316\n",
      "Epoch 29/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.8783 - accuracy: 0.5500 - val_loss: 0.0728 - val_accuracy: 0.9895\n",
      "Epoch 30/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.5566 - accuracy: 0.6417 - val_loss: 0.9317 - val_accuracy: 0.7947\n",
      "Epoch 31/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.5570 - accuracy: 0.6500 - val_loss: 0.0615 - val_accuracy: 0.9895\n",
      "Epoch 32/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.8202 - accuracy: 0.6542 - val_loss: 0.4949 - val_accuracy: 0.8368\n",
      "Epoch 33/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.7873 - accuracy: 0.6375 - val_loss: 0.7504 - val_accuracy: 0.7579\n",
      "Epoch 34/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4222 - accuracy: 0.6542 - val_loss: 0.2189 - val_accuracy: 0.9579\n",
      "Epoch 35/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0268 - accuracy: 0.7167 - val_loss: 0.1687 - val_accuracy: 0.9421\n",
      "Epoch 36/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0499 - accuracy: 0.7458 - val_loss: 0.0773 - val_accuracy: 0.9842\n",
      "Epoch 37/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.3217 - accuracy: 0.6333 - val_loss: 0.0538 - val_accuracy: 0.9947\n",
      "Epoch 38/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.7610 - accuracy: 0.6125 - val_loss: 0.4306 - val_accuracy: 0.8789\n",
      "Epoch 39/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.6772 - accuracy: 0.7125 - val_loss: 0.0372 - val_accuracy: 0.9947\n",
      "Epoch 40/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.6786 - accuracy: 0.6833 - val_loss: 0.2172 - val_accuracy: 0.9526\n",
      "Epoch 41/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.1075 - accuracy: 0.7333 - val_loss: 0.4709 - val_accuracy: 0.8579\n",
      "Epoch 42/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.9534 - accuracy: 0.6958 - val_loss: 0.1155 - val_accuracy: 0.9684\n",
      "Epoch 43/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.1472 - accuracy: 0.6667 - val_loss: 0.0320 - val_accuracy: 0.9947\n",
      "Epoch 44/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.3904 - accuracy: 0.7250 - val_loss: 4.1174 - val_accuracy: 0.0842\n",
      "Epoch 45/45\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.1981 - accuracy: 0.5917 - val_loss: 0.0592 - val_accuracy: 0.9789\n"
     ]
    }
   ],
   "source": [
    "History = model.fit(train_generator,\n",
    "      steps_per_epoch=2,\n",
    "      epochs=45,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esfUKtys1krP"
   },
   "source": [
    "Save the model\n",
    "\n",
    "Note: to load model on raspberry pi see: https://www.tensorflow.org/tutorials/keras/save_and_load\n",
    "\n",
    "\"Reload a fresh Keras model from the saved model:\n",
    "\n",
    "new_model = tf.keras.models.load_model('saved_model/my_model') \n",
    "\n",
    "...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAdU1EVwwNxG",
    "outputId": "73cd81fe-bb20-44cb-cea5-a9e55587f812"
   },
   "outputs": [],
   "source": [
    "#!mkdir -p saved_model\n",
    "#model.save('saved_model/my_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uj5qSfeR1sQ-"
   },
   "source": [
    "## Accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRjMyh-68IOB"
   },
   "source": [
    "Let's evaluate the accuracy of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyA2zQcVKnZE",
    "outputId": "6c529e68-d490-4850-fdfe-b7db22fe25c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.5916666984558105\n",
      "Training loss:  2.1980926990509033\n",
      "Validation accuracy:  0.9789474010467529\n",
      "Validation loss:  0.059243205934762955\n"
     ]
    }
   ],
   "source": [
    "acc = History.history['accuracy'][-1]\n",
    "val_acc = History.history['val_accuracy'][-1]\n",
    "loss = History.history['loss'][-1]\n",
    "val_loss = History.history['val_loss'][-1]\n",
    "\n",
    "print(\"Training accuracy: \", acc)\n",
    "print(\"Training loss: \", loss)\n",
    "\n",
    "print(\"Validation accuracy: \", val_acc)\n",
    "print(\"Validation loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CS437 Unsnoozable ML model",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
